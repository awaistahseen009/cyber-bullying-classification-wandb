{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19c575f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Awais\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Awais\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Awais\\anaconda3\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import string\n",
    "import re\n",
    "import tensorflow as tf\n",
    "from keras.layers import LSTM , Bidirectional , Embedding, Dense , Input\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "838175a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('data\\cyberbullying_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cee17ea3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>cyberbullying_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In other words #katandandre, your food was cra...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Why is #aussietv so white? #MKR #theblock #ImA...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@XochitlSuckkks a classy whore? Or more red ve...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Jason_Gio meh. :P  thanks for the heads up, b...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@RudhoeEnglish This is an ISIS account pretend...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text cyberbullying_type\n",
       "0  In other words #katandandre, your food was cra...  not_cyberbullying\n",
       "1  Why is #aussietv so white? #MKR #theblock #ImA...  not_cyberbullying\n",
       "2  @XochitlSuckkks a classy whore? Or more red ve...  not_cyberbullying\n",
       "3  @Jason_Gio meh. :P  thanks for the heads up, b...  not_cyberbullying\n",
       "4  @RudhoeEnglish This is an ISIS account pretend...  not_cyberbullying"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "124cf325",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns= ['text','target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f77fd7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In other words #katandandre, your food was cra...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Why is #aussietv so white? #MKR #theblock #ImA...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@XochitlSuckkks a classy whore? Or more red ve...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Jason_Gio meh. :P  thanks for the heads up, b...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@RudhoeEnglish This is an ISIS account pretend...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text             target\n",
       "0  In other words #katandandre, your food was cra...  not_cyberbullying\n",
       "1  Why is #aussietv so white? #MKR #theblock #ImA...  not_cyberbullying\n",
       "2  @XochitlSuckkks a classy whore? Or more red ve...  not_cyberbullying\n",
       "3  @Jason_Gio meh. :P  thanks for the heads up, b...  not_cyberbullying\n",
       "4  @RudhoeEnglish This is an ISIS account pretend...  not_cyberbullying"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "098444b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['not_cyberbullying', 'gender', 'religion', 'other_cyberbullying',\n",
       "       'age', 'ethnicity'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d69cb1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47692, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6b5869b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text      0\n",
       "target    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "edd2eb7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ef37890",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ec7082",
   "metadata": {},
   "source": [
    "# Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f57c1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer=PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0632d411",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize , sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a6b7ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = word_tokenize(text)\n",
    "    text = [word for word in text if not re.match(r'#\\w+', word)]\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    text = [word.translate(translator) for word in text]\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    text = [word for word in text if word not in stop_words]\n",
    "    text=[stemmer.stem(word) for word in text]\n",
    "    cleaned_text = \" \".join(text)\n",
    "    return cleaned_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a196edb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' aussietv white   mkr  theblock  imacelebrityau  today  sunris  studio10  neighbour  wonderlandten  etc'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess(df['text'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9b9f307",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_text']=df['text'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3411cb59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In other words #katandandre, your food was cra...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>word  katandandr  food crapilici   mkr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Why is #aussietv so white? #MKR #theblock #ImA...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>aussietv white   mkr  theblock  imacelebritya...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@XochitlSuckkks a classy whore? Or more red ve...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>xochitlsuckkk classi whore  red velvet cupcak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Jason_Gio meh. :P  thanks for the heads up, b...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>jasongio meh   p thank head  concern anoth an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@RudhoeEnglish This is an ISIS account pretend...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>rudhoeenglish isi account pretend kurdish acc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text             target  \\\n",
       "0  In other words #katandandre, your food was cra...  not_cyberbullying   \n",
       "1  Why is #aussietv so white? #MKR #theblock #ImA...  not_cyberbullying   \n",
       "2  @XochitlSuckkks a classy whore? Or more red ve...  not_cyberbullying   \n",
       "3  @Jason_Gio meh. :P  thanks for the heads up, b...  not_cyberbullying   \n",
       "4  @RudhoeEnglish This is an ISIS account pretend...  not_cyberbullying   \n",
       "\n",
       "                                          clean_text  \n",
       "0             word  katandandr  food crapilici   mkr  \n",
       "1   aussietv white   mkr  theblock  imacelebritya...  \n",
       "2     xochitlsuckkk classi whore  red velvet cupcak   \n",
       "3   jasongio meh   p thank head  concern anoth an...  \n",
       "4   rudhoeenglish isi account pretend kurdish acc...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da17d0e",
   "metadata": {},
   "source": [
    "# Encoding the target categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e619ade3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,value in enumerate(df['target'].unique()): \n",
    "    df['target'].replace({value:i},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e6660e70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In other words #katandandre, your food was cra...</td>\n",
       "      <td>0</td>\n",
       "      <td>word  katandandr  food crapilici   mkr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Why is #aussietv so white? #MKR #theblock #ImA...</td>\n",
       "      <td>0</td>\n",
       "      <td>aussietv white   mkr  theblock  imacelebritya...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@XochitlSuckkks a classy whore? Or more red ve...</td>\n",
       "      <td>0</td>\n",
       "      <td>xochitlsuckkk classi whore  red velvet cupcak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Jason_Gio meh. :P  thanks for the heads up, b...</td>\n",
       "      <td>0</td>\n",
       "      <td>jasongio meh   p thank head  concern anoth an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@RudhoeEnglish This is an ISIS account pretend...</td>\n",
       "      <td>0</td>\n",
       "      <td>rudhoeenglish isi account pretend kurdish acc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target  \\\n",
       "0  In other words #katandandre, your food was cra...       0   \n",
       "1  Why is #aussietv so white? #MKR #theblock #ImA...       0   \n",
       "2  @XochitlSuckkks a classy whore? Or more red ve...       0   \n",
       "3  @Jason_Gio meh. :P  thanks for the heads up, b...       0   \n",
       "4  @RudhoeEnglish This is an ISIS account pretend...       0   \n",
       "\n",
       "                                          clean_text  \n",
       "0             word  katandandr  food crapilici   mkr  \n",
       "1   aussietv white   mkr  theblock  imacelebritya...  \n",
       "2     xochitlsuckkk classi whore  red velvet cupcak   \n",
       "3   jasongio meh   p thank head  concern anoth an...  \n",
       "4   rudhoeenglish isi account pretend kurdish acc...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e827189",
   "metadata": {},
   "source": [
    "# Tokenizing the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cd163c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a6a8cdcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(df['clean_text'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ccbda5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences(df['clean_text'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ec0ecea6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53268"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "590c0e28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[99, 2158, 638, 18494, 35],\n",
       " [18495, 36, 35, 12413, 7350, 168, 12414, 18496, 6015, 18497, 236]]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences[:2] # Preview of sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a738b0",
   "metadata": {},
   "source": [
    "# Padding the sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6d3d0cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "02d12c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len=40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dd0af5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_sequences=pad_sequences(sequences, maxlen=max_len, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "916fac29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47656, 40)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_sequences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "86431230",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3f43644b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=padded_sequences\n",
    "y=to_categorical(df['target'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3a36c961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x has shape: (47656, 40) and y has shape :(47656, 6)\n"
     ]
    }
   ],
   "source": [
    "print(f'x has shape: {x.shape} and y has shape :{y.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3cc514c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "240f8bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test =  train_test_split(x, y , test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a6f5072d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traning has samples: 42890 , Testing has samples: 4766\n"
     ]
    }
   ],
   "source": [
    "print(f'Traning has samples: {x_train.shape[0]} , Testing has samples: {x_test.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c4afc6",
   "metadata": {},
   "source": [
    "# Model Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b2139b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(embedding_dim , latent_dim , vocab_size , max_len, target_values):\n",
    "    inp=Input(max_len, )\n",
    "    emb=Embedding(vocab_size, embedding_dim , input_length=max_len)(inp)\n",
    "    lstm_1=Bidirectional(LSTM(latent_dim, return_sequences=True))(emb)\n",
    "    lstm_2=Bidirectional(LSTM(latent_dim))(lstm_1)\n",
    "    out=Dense(target_values, activation='softmax')(lstm_2)\n",
    "    model=Model(inp , out)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1e332cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wandb in c:\\users\\awais\\anaconda3\\lib\\site-packages (0.16.2)\n",
      "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in c:\\users\\awais\\anaconda3\\lib\\site-packages (from wandb) (3.1.40)\n",
      "Requirement already satisfied: setproctitle in c:\\users\\awais\\anaconda3\\lib\\site-packages (from wandb) (1.3.3)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in c:\\users\\awais\\anaconda3\\lib\\site-packages (from wandb) (2.28.1)\n",
      "Requirement already satisfied: psutil>=5.0.0 in c:\\users\\awais\\anaconda3\\lib\\site-packages (from wandb) (5.9.0)\n",
      "Requirement already satisfied: appdirs>=1.4.3 in c:\\users\\awais\\anaconda3\\lib\\site-packages (from wandb) (1.4.4)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\awais\\anaconda3\\lib\\site-packages (from wandb) (6.0)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in c:\\users\\awais\\anaconda3\\lib\\site-packages (from wandb) (1.40.0)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.1 in c:\\users\\awais\\anaconda3\\lib\\site-packages (from wandb) (8.0.4)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in c:\\users\\awais\\anaconda3\\lib\\site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in c:\\users\\awais\\anaconda3\\lib\\site-packages (from wandb) (4.23.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\awais\\anaconda3\\lib\\site-packages (from wandb) (65.6.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\awais\\anaconda3\\lib\\site-packages (from Click!=8.0.0,>=7.1->wandb) (0.4.6)\n",
      "Requirement already satisfied: six>=1.4.0 in c:\\users\\awais\\anaconda3\\lib\\site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\awais\\anaconda3\\lib\\site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\awais\\anaconda3\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\awais\\anaconda3\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\awais\\anaconda3\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\awais\\anaconda3\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2.0.4)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\awais\\anaconda3\\lib\\site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dfd6a93c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mawaistahseen009\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: C:\\Users\\Awais\\.netrc\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fd7e0ec1c364a41992e0c0df25e6d7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011111111111111112, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Awais\\Desktop\\Machine_learning_ETEP\\Cyberbullying_Classification\\cyber-bullying-classification\\wandb\\run-20240204_124259-5vfpyhdr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/awaistahseen009/Cyberbullying_Classification_v2/runs/5vfpyhdr' target=\"_blank\">fragrant-sound-1</a></strong> to <a href='https://wandb.ai/awaistahseen009/Cyberbullying_Classification_v2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/awaistahseen009/Cyberbullying_Classification_v2' target=\"_blank\">https://wandb.ai/awaistahseen009/Cyberbullying_Classification_v2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/awaistahseen009/Cyberbullying_Classification_v2/runs/5vfpyhdr' target=\"_blank\">https://wandb.ai/awaistahseen009/Cyberbullying_Classification_v2/runs/5vfpyhdr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/awaistahseen009/Cyberbullying_Classification_v2/runs/5vfpyhdr?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x2d788222f20>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login(key=\"ba7560e300da0402f0be06a309b33c370c62acfe\")\n",
    "wandb.init(project='Cyberbullying_Classification_v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f05628cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.config={\n",
    "'batch_size':256,\n",
    "'epochs':30,\n",
    "'latent_dim':150,\n",
    "'embedding_dim':300,\n",
    "'optimizer':'rmsprop',\n",
    "}\n",
    "configuration=wandb.config\n",
    "from wandb.keras import WandbCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "293eac7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size=len(tokenizer.word_index)\n",
    "target_values=len(df['target'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2e52bb03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "58cbcde7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Awais\\anaconda3\\lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model=build_model(configuration['embedding_dim'], configuration['latent_dim'], vocab_size+1 ,max_len, target_values )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c1eeac65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Awais\\anaconda3\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=configuration['optimizer'], loss='categorical_crossentropy' , metrics=['accuracy'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a8fa1d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_s = EarlyStopping(monitor='val_loss',verbose=1,patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "93fba83d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "WARNING:tensorflow:From C:\\Users\\Awais\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Awais\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "135/135 [==============================] - ETA: 0s - loss: 0.8699 - accuracy: 0.6315"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Awais\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Awais\\Desktop\\Machine_learning_ETEP\\Cyberbullying_Classification\\cyber-bullying-classification\\wandb\\run-20240204_124259-5vfpyhdr\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Awais\\Desktop\\Machine_learning_ETEP\\Cyberbullying_Classification\\cyber-bullying-classification\\wandb\\run-20240204_124259-5vfpyhdr\\files\\model-best\\assets\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (C:\\Users\\Awais\\Desktop\\Machine_learning_ETEP\\Cyberbullying_Classification\\cyber-bullying-classification\\wandb\\run-20240204_124259-5vfpyhdr\\files\\model-best)... Done. 0.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - 175s 1s/step - loss: 0.8699 - accuracy: 0.6315 - val_loss: 0.6792 - val_accuracy: 0.7427\n",
      "Epoch 2/30\n",
      "135/135 [==============================] - ETA: 0s - loss: 0.4326 - accuracy: 0.8169"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Awais\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Awais\\Desktop\\Machine_learning_ETEP\\Cyberbullying_Classification\\cyber-bullying-classification\\wandb\\run-20240204_124259-5vfpyhdr\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Awais\\Desktop\\Machine_learning_ETEP\\Cyberbullying_Classification\\cyber-bullying-classification\\wandb\\run-20240204_124259-5vfpyhdr\\files\\model-best\\assets\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (C:\\Users\\Awais\\Desktop\\Machine_learning_ETEP\\Cyberbullying_Classification\\cyber-bullying-classification\\wandb\\run-20240204_124259-5vfpyhdr\\files\\model-best)... Done. 0.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - 149s 1s/step - loss: 0.4326 - accuracy: 0.8169 - val_loss: 0.4351 - val_accuracy: 0.8071\n",
      "Epoch 3/30\n",
      "135/135 [==============================] - 119s 880ms/step - loss: 0.3443 - accuracy: 0.8612 - val_loss: 0.5497 - val_accuracy: 0.7940\n",
      "Epoch 4/30\n",
      "135/135 [==============================] - 116s 861ms/step - loss: 0.2886 - accuracy: 0.8861 - val_loss: 0.5583 - val_accuracy: 0.7967\n",
      "Epoch 5/30\n",
      "135/135 [==============================] - 116s 864ms/step - loss: 0.2461 - accuracy: 0.9048 - val_loss: 0.4790 - val_accuracy: 0.8268\n",
      "Epoch 6/30\n",
      "135/135 [==============================] - 117s 867ms/step - loss: 0.2101 - accuracy: 0.9209 - val_loss: 0.6033 - val_accuracy: 0.8122\n",
      "Epoch 7/30\n",
      "135/135 [==============================] - 118s 873ms/step - loss: 0.1821 - accuracy: 0.9302 - val_loss: 0.6194 - val_accuracy: 0.7940\n",
      "Epoch 8/30\n",
      "135/135 [==============================] - 115s 853ms/step - loss: 0.1624 - accuracy: 0.9367 - val_loss: 0.5907 - val_accuracy: 0.8055\n",
      "Epoch 9/30\n",
      "135/135 [==============================] - 119s 879ms/step - loss: 0.1432 - accuracy: 0.9434 - val_loss: 0.7473 - val_accuracy: 0.7843\n",
      "Epoch 10/30\n",
      "135/135 [==============================] - 115s 854ms/step - loss: 0.1340 - accuracy: 0.9469 - val_loss: 0.6226 - val_accuracy: 0.7935\n",
      "Epoch 11/30\n",
      "135/135 [==============================] - 116s 861ms/step - loss: 0.1172 - accuracy: 0.9514 - val_loss: 0.8275 - val_accuracy: 0.7665\n",
      "Epoch 12/30\n",
      "135/135 [==============================] - 116s 861ms/step - loss: 0.1103 - accuracy: 0.9526 - val_loss: 0.7116 - val_accuracy: 0.8101\n",
      "Epoch 12: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2d79a0aa050>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          epochs=configuration['epochs'] , \n",
    "          batch_size=configuration['batch_size'],\n",
    "          validation_split=0.2,\n",
    "          callbacks=[early_s, WandbCallback()]\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "81f1fdcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149/149 [==============================] - 6s 40ms/step - loss: 0.6704 - accuracy: 0.8168\n",
      "Evaluation Loss: 0.6704307794570923\n",
      "Evaluation Accuracy: 0.8168275356292725\n"
     ]
    }
   ],
   "source": [
    "evaluation_result = model.evaluate(x_test, y_test)\n",
    "\n",
    "# Printing the evaluation results\n",
    "print(\"Evaluation Loss:\", evaluation_result[0])\n",
    "print(\"Evaluation Accuracy:\", evaluation_result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "054494ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('cyber_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bb44fb93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='43.612 MB of 398.380 MB uploaded\\r'), FloatProgress(value=0.10947414705059802, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▅▆▇▇▇██████</td></tr><tr><td>epoch</td><td>▁▂▂▃▄▄▅▅▆▇▇█</td></tr><tr><td>loss</td><td>█▄▃▃▂▂▂▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▆▅▅█▇▅▆▄▅▃▇</td></tr><tr><td>val_loss</td><td>▅▁▃▃▂▄▄▄▇▄█▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.95255</td></tr><tr><td>best_epoch</td><td>1</td></tr><tr><td>best_val_loss</td><td>0.43506</td></tr><tr><td>epoch</td><td>11</td></tr><tr><td>loss</td><td>0.11034</td></tr><tr><td>val_accuracy</td><td>0.8101</td></tr><tr><td>val_loss</td><td>0.71156</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fragrant-sound-1</strong> at: <a href='https://wandb.ai/awaistahseen009/Cyberbullying_Classification_v2/runs/5vfpyhdr' target=\"_blank\">https://wandb.ai/awaistahseen009/Cyberbullying_Classification_v2/runs/5vfpyhdr</a><br/> View job at <a href='https://wandb.ai/awaistahseen009/Cyberbullying_Classification_v2/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjEzNjk2OTc2MQ==/version_details/v0' target=\"_blank\">https://wandb.ai/awaistahseen009/Cyberbullying_Classification_v2/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjEzNjk2OTc2MQ==/version_details/v0</a><br/>Synced 6 W&B file(s), 1 media file(s), 12 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240204_124259-5vfpyhdr\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98d3299",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
